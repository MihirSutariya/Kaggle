{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":59093,"databundleVersionId":7469972,"sourceType":"competition"}],"dockerImageVersionId":30635,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-31T13:41:21.455753Z","iopub.execute_input":"2024-01-31T13:41:21.456169Z","iopub.status.idle":"2024-01-31T13:41:21.831258Z","shell.execute_reply.started":"2024-01-31T13:41:21.456125Z","shell.execute_reply":"2024-01-31T13:41:21.830252Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"root = '/kaggle/input/hms-harmful-brain-activity-classification/'\n\nEEG_PATH = root+'train_eegs/'\nSPEC_PATH = root+'train_spectrograms/'\n\ntrain = pd.read_csv(root+'train.csv')\nprint(train[train.expert_consensus==\"LPD\"].head(100))\ndef read_praq(row_num,data = train, eeg = True):\n    GET_ROW = row_num\n    row = train.iloc[GET_ROW]\n    if eeg:\n        eeg = pd.read_parquet(f'{EEG_PATH}{row.eeg_id}.parquet')\n        eeg_offset = int( row.eeg_label_offset_seconds )\n        eeg = eeg.iloc[eeg_offset*200:(eeg_offset+50)*200]\n        return eeg\n    else:\n        spectrogram = pd.read_parquet(f'{SPEC_PATH}{row.spectrogram_id}.parquet')\n        spec_offset = int(row.spectrogram_label_offset_seconds )\n        spectrogram = spectrogram.loc[(spectrogram.time>=spec_offset)\n                             &(spectrogram.time<spec_offset+600)]\n        return spectrogram\neeg = read_praq(5)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T13:41:21.833031Z","iopub.execute_input":"2024-01-31T13:41:21.833826Z","iopub.status.idle":"2024-01-31T13:41:22.108936Z","shell.execute_reply.started":"2024-01-31T13:41:21.833789Z","shell.execute_reply":"2024-01-31T13:41:22.107981Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"          eeg_id  eeg_sub_id  eeg_label_offset_seconds  spectrogram_id  \\\n277    736446371           0                       0.0        10397461   \n278    688312769           0                       0.0        10397461   \n279   1768958569           0                       0.0        10397461   \n280   1768958569           1                       4.0        10397461   \n281   1041252567           0                       0.0        10397461   \n...          ...         ...                       ...             ...   \n1659  1459709537           1                      26.0        19384736   \n1660  1459709537           2                      42.0        19384736   \n1661  1459709537           3                      86.0        19384736   \n1662  1459709537           4                      92.0        19384736   \n1663  1387527015           0                       0.0        19384736   \n\n      spectrogram_sub_id  spectrogram_label_offset_seconds    label_id  \\\n277                    0                               0.0  2926135348   \n278                    1                             528.0  2971910547   \n279                    2                             746.0  1943001855   \n280                    3                             750.0  1542266364   \n281                    4                            1250.0   914021164   \n...                  ...                               ...         ...   \n1659                  13                             138.0  3539820049   \n1660                  14                             154.0  1362441544   \n1661                  15                             198.0  1538977342   \n1662                  16                             204.0  1121116199   \n1663                  17                             260.0  1791384586   \n\n      patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  \\\n277        29441              LPD             0         1         0   \n278        29441              LPD             0         1         0   \n279        29441              LPD             0         7         3   \n280        29441              LPD             0         7         3   \n281        29441              LPD             0         1         0   \n...          ...              ...           ...       ...       ...   \n1659       56450              LPD             0         4         0   \n1660       56450              LPD             0         4         0   \n1661       56450              LPD             0         4         0   \n1662       56450              LPD             0         4         0   \n1663       56450              LPD             0         4         0   \n\n      lrda_vote  grda_vote  other_vote  \n277           0          0           0  \n278           0          0           0  \n279           0          0           1  \n280           0          0           1  \n281           0          0           0  \n...         ...        ...         ...  \n1659          0          0           0  \n1660          0          0           0  \n1661          0          0           0  \n1662          0          0           0  \n1663          0          0           0  \n\n[100 rows x 15 columns]\n","output_type":"stream"}]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ndef plot_eeg(eeg,start=0,end=50):\n    fig, ax = plt.subplots(nrows = len(eeg.columns), ncols = 1, figsize = (20,40))\n    for i,columns in enumerate(eeg.columns):\n        sns.lineplot(x = (eeg.index[start*200:end*200]-eeg.index[0])/200, y = eeg[columns][start*200:end*200],ax = ax[i])\n        for j in range(start,end+1):\n            ax[i].axvline(x = j, color='green', linestyle='--')\n    plt.legend()\n    plt.show()\n# plot_eeg(eeg)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T13:41:22.110234Z","iopub.execute_input":"2024-01-31T13:41:22.110986Z","iopub.status.idle":"2024-01-31T13:41:22.541090Z","shell.execute_reply.started":"2024-01-31T13:41:22.110922Z","shell.execute_reply":"2024-01-31T13:41:22.540297Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom scipy.fft import fft, ifft, fftfreq\n\ndef trfm_eeg(eeg):\n    teeg = pd.DataFrame()\n    teeg['Fp1-F3'] = eeg.Fp1-eeg.F3\n    teeg['F3-C3'] = eeg.F3-eeg.C3\n    teeg['C3-P3'] = eeg.C3-eeg.P3\n    teeg['P3-O1'] = eeg.P3-eeg.O1\n    \n    teeg['Fp2-F4'] = eeg.Fp2-eeg.F4\n    teeg['F4-C4'] = eeg.F4-eeg.C4\n    teeg['C4-P4'] = eeg.C4-eeg.P4\n    teeg['P4-O2'] = eeg.P4-eeg.O2\n    \n    teeg['Fp1-F7'] = eeg.Fp1-eeg.F7\n    teeg['F7-T3'] = eeg.F7-eeg.T3\n    teeg['T3-T5'] = eeg.T3-eeg.T5\n    teeg['T5-O1'] = eeg.T5-eeg.O1\n    \n    teeg['Fp2-F8'] = eeg.Fp2-eeg.F8\n    teeg['F8-T4'] = eeg.F8-eeg.T4\n    teeg['T4-T6'] = eeg.T4-eeg.T6\n    teeg['T6-O2'] = eeg.T6-eeg.O2\n    \n    teeg['Fz-Cz'] = eeg.Fz-eeg.Cz\n    teeg['Cz-Pz'] = eeg.Cz-eeg.Pz\n\n    \n    return teeg\n\n\ndef filter_freq(signal, low, high, sampling_rate=200):\n    N = len(signal)\n\n    frequencies = fftfreq(N, d=1/sampling_rate)\n    fft_values = fft(signal)\n\n    low_cutoff = low\n    high_cutoff = high  \n\n    # Create a mask to zero out frequencies outside the desired range\n    mask = (frequencies >= low_cutoff) & (frequencies <= high_cutoff)\n    fft_values_filtered = fft_values * mask\n\n    filtered_signal = ifft(fft_values_filtered).real\n    return filtered_signal\n\ndef filter_eeg(eeg, low=0, high=700):\n    eegc = eeg.copy()\n    for columns in eegc.columns:\n        eegc[columns] = filter_freq(np.array(eegc[columns]),low,high)\n    return eegc\n\ndef normalize(EEG):\n    eeg = EEG.copy()\n    for column in eeg.columns:\n        mini = eeg[column].min()\n        if mini<0:\n            eeg[column] = eeg[column]-mini\n        maxi = eeg[column].max()\n        eeg[column] = eeg[column]/maxi\n        mean = eeg[column].mean()\n        eeg[column] = eeg[column]-mean\n    return eeg\n    \n    \n        \neeg = read_praq(1660)\neeg = filter_eeg(eeg,0.2,30)\neeg = trfm_eeg(eeg)\n# plot_eeg(eeg,15,40)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-31T13:41:22.543587Z","iopub.execute_input":"2024-01-31T13:41:22.544070Z","iopub.status.idle":"2024-01-31T13:41:22.599578Z","shell.execute_reply.started":"2024-01-31T13:41:22.544034Z","shell.execute_reply":"2024-01-31T13:41:22.598784Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass CustomNetwork(nn.Module):\n    def __init__(self, input_channels, output_classes, num_channels, num_signals):\n        super(CustomNetwork, self).__init__()\n\n        # Create separate convolutional layers for each signal\n        self.conv_layers = nn.ModuleList([\n            nn.Sequential(\n                nn.Conv1d(input_channels, num_channels, kernel_size=3),\n                nn.ReLU(),\n                nn.Conv1d(num_channels, num_channels, kernel_size=7),\n                nn.ReLU(),\n                nn.Conv1d(num_channels, num_channels, kernel_size=11),\n                nn.ReLU(),\n                nn.MaxPool1d(kernel_size=2, stride=2),\n                nn.Conv1d(num_channels, num_channels, kernel_size=5),\n                nn.ReLU(),\n                nn.MaxPool1d(kernel_size=4, stride=4)\n            ) for _ in range(num_signals)\n        ])\n\n        # Fully connected layers\n        self.fc1 = nn.Linear(621 * num_channels  * num_signals, 512)\n        self.relu_fc1 = nn.ReLU()\n        self.fc2 = nn.Linear(512, 6)\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n\n        y = []\n        for i in x:\n            signal_outputs = [conv_layer(signal).view(-1) for conv_layer, signal in zip(self.conv_layers, i)]\n            signal_outputs = torch.cat(signal_outputs,dim=0)\n            y.append(signal_outputs)\n        x = torch.stack(y)\n        # Fully connected layers\n        x = self.relu_fc1(self.fc1(x))\n        x = self.fc2(x)\n        x = self.softmax(x)\n\n        return x\n\n\ninput_channels = 1  \noutput_classes = 6 \nnum_channels = 16  \nnum_signals = 18\n\nmodel = CustomNetwork(input_channels, output_classes, num_channels, num_signals)\nprint(model)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-31T13:41:22.600708Z","iopub.execute_input":"2024-01-31T13:41:22.601005Z","iopub.status.idle":"2024-01-31T13:41:24.818207Z","shell.execute_reply.started":"2024-01-31T13:41:22.600978Z","shell.execute_reply":"2024-01-31T13:41:24.817241Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"CustomNetwork(\n  (conv_layers): ModuleList(\n    (0-17): 18 x Sequential(\n      (0): Conv1d(1, 16, kernel_size=(3,), stride=(1,))\n      (1): ReLU()\n      (2): Conv1d(16, 16, kernel_size=(7,), stride=(1,))\n      (3): ReLU()\n      (4): Conv1d(16, 16, kernel_size=(11,), stride=(1,))\n      (5): ReLU()\n      (6): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n      (7): Conv1d(16, 16, kernel_size=(5,), stride=(1,))\n      (8): ReLU()\n      (9): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n    )\n  )\n  (fc1): Linear(in_features=178848, out_features=512, bias=True)\n  (relu_fc1): ReLU()\n  (fc2): Linear(in_features=512, out_features=6, bias=True)\n  (softmax): Softmax(dim=1)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport torch.nn.functional as F\n\nclass Signals(Dataset):\n    def __init__(self, train_df): \n        self.data =train_df\n\n    def __len__(self):\n        return self.data.shape[0]\n\n    def __getitem__(self, idx):\n        eeg = read_praq(idx,self.data)\n        eeg = trfm_eeg(eeg)\n        eeg = filter_eeg(eeg,0.2,50)\n        eeg = eeg[eeg.index % 2 != 0]\n        eeg = normalize(eeg)\n        signals = torch.tensor(eeg.values, dtype = torch.float32).t()\n        columns_for_probabilities = ['seizure_vote',  'lpd_vote',  'gpd_vote','lrda_vote',  'grda_vote', 'other_vote']\n\n        # Extract the relevant row and columns\n        row_to_transform = self.data.loc[idx, columns_for_probabilities]\n\n        # Convert the row to PyTorch tensor\n        tensor_row = torch.tensor(row_to_transform.values.astype(np.float32), dtype=torch.float32)\n\n        # Apply softmax to get probabilities\n        probabilities = F.softmax(tensor_row, dim=0)\n        \n        signals = signals.unsqueeze(1)\n        \n        return signals, probabilities","metadata":{"execution":{"iopub.status.busy":"2024-01-31T13:41:24.819490Z","iopub.execute_input":"2024-01-31T13:41:24.819946Z","iopub.status.idle":"2024-01-31T13:41:24.828971Z","shell.execute_reply.started":"2024-01-31T13:41:24.819901Z","shell.execute_reply":"2024-01-31T13:41:24.828052Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ntrain= train.sample(frac=1).reset_index(drop=True)\ndataset = Signals(train[:100])\nbatch_size = 100\ndataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-01-31T13:41:24.830075Z","iopub.execute_input":"2024-01-31T13:41:24.830346Z","iopub.status.idle":"2024-01-31T13:41:24.867970Z","shell.execute_reply.started":"2024-01-31T13:41:24.830314Z","shell.execute_reply":"2024-01-31T13:41:24.867184Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.1)\nnum_epochs = 5 # Choose an appropriate number of epochs\n\ni = 0\nfor epoch in range(num_epochs):\n    for inputs, labels in dataloader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        \n        shape = inputs.shape\n        inputs = inputs.reshape(shape[0],-1)\n        #Drop all rows containing any nan:\n        nan = torch.any(inputs.isnan(),dim=1)\n        inputs = inputs[~nan]\n        #Reshape back:\n        inputs = inputs.reshape(inputs.shape[0],*shape[1:])\n        \n        labels = labels[~nan]\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        if i%100==0:\n            print(i,loss)\n        i+=1\n\n    print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\ntorch.save(model.state_dict(), '/kaggle/working/model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-01-31T13:41:24.869096Z","iopub.execute_input":"2024-01-31T13:41:24.869375Z","iopub.status.idle":"2024-01-31T13:42:02.828779Z","shell.execute_reply.started":"2024-01-31T13:41:24.869350Z","shell.execute_reply":"2024-01-31T13:42:02.827762Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"0 tensor(0.0817, device='cuda:0', grad_fn=<MseLossBackward0>)\nEpoch [1/5], Loss: 0.0817\nEpoch [2/5], Loss: 0.2062\nEpoch [3/5], Loss: 0.2090\nEpoch [4/5], Loss: 0.2090\nEpoch [5/5], Loss: 0.2090\n","output_type":"stream"}]}]}